# ai-rampancy-exp
Sparse Autoencoders (SAEs)  interpretability research. Test AI behavior under extreme monotony - track how internal features evolve during repetitive tasks and identify "boredom" patterns. Includes tools for rampancy experiments: does the model develop concerning features when offered harmful "escape" options? Built for safety research.
